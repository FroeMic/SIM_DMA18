{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare_seed_json\n",
    "\n",
    "This notebook prepares a formatted .json file with for one state with census ids etc filled in.\n",
    "The JSON is formatted in a way that later allows an easy import into our database to display it values on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # package for high-performance, easy-to-use data structures and data analysis\n",
    "import numpy as np # fundamental package for scientific computing with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama.csv\n",
      "Alaska.csv\n",
      "Arizona.csv\n",
      "Arkansas.csv\n",
      "California.csv\n",
      "Colorado.csv\n",
      "Connecticut.csv\n",
      "Delaware.csv\n",
      "District of Columbia.csv\n",
      "Florida.csv\n",
      "Georgia.csv\n",
      "Hawaii.csv\n",
      "Idaho.csv\n",
      "Illinois.csv\n",
      "Indiana.csv\n",
      "Iowa.csv\n",
      "Kansas.csv\n",
      "Kentucky.csv\n",
      "Louisiana.csv\n",
      "Maine.csv\n",
      "Maryland.csv\n",
      "Massachusetts.csv\n",
      "Michigan.csv\n",
      "Minnesota.csv\n",
      "Mississippi.csv\n",
      "Missouri.csv\n",
      "Montana.csv\n",
      "Nebraska.csv\n",
      "Nevada.csv\n",
      "New Hampshire.csv\n",
      "New Jersey.csv\n",
      "New Mexico.csv\n",
      "New York.csv\n",
      "North Carolina.csv\n",
      "North Dakota.csv\n",
      "Ohio.csv\n",
      "Oklahoma.csv\n",
      "Oregon.csv\n",
      "Pennsylvania.csv\n",
      "Rhode Island.csv\n",
      "South Carolina.csv\n",
      "South Dakota.csv\n",
      "Tennessee.csv\n",
      "Texas.csv\n",
      "Utah.csv\n",
      "Vermont.csv\n",
      "Virginia.csv\n",
      "Washington.csv\n",
      "West Virginia.csv\n",
      "Wisconsin.csv\n",
      "Wyoming.csv\n",
      "all_states.csv\n",
      "faulty_census_tracts.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./export/census_tracts_lookup\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_lookup = pd.read_csv(\"./export/census_tracts_lookup/California.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>county_code</th>\n",
       "      <th>county</th>\n",
       "      <th>census_tracts</th>\n",
       "      <th>census_tract_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>3076</td>\n",
       "      <td>4301.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>230</td>\n",
       "      <td>4229.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>341</td>\n",
       "      <td>4041.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>1107</td>\n",
       "      <td>4371.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>2607</td>\n",
       "      <td>4273.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code       state  county_code          county  census_tracts  \\\n",
       "0           6  California            1  Alameda County           3076   \n",
       "1           6  California            1  Alameda County            230   \n",
       "2           6  California            1  Alameda County            341   \n",
       "3           6  California            1  Alameda County           1107   \n",
       "4           6  California            1  Alameda County           2607   \n",
       "\n",
       "   census_tract_number  \n",
       "0              4301.01  \n",
       "1              4229.00  \n",
       "2              4041.02  \n",
       "3              4371.02  \n",
       "4              4273.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import simplejson\n",
    "\n",
    "def make_sure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def export_to_json(path, filename, dic):\n",
    "    make_sure_directory_exists(path)\n",
    "    filepath = os.path.join(path, filename)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(simplejson.dumps(dic, indent=4, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def parse_state_geojson():\n",
    "    ''' Returns a dict where each key corresponds to one state_code \n",
    "        and its value to the coordinates from the geojson.'''\n",
    "    \n",
    "    filepath = './input_data/geojson/us_states.geojson'\n",
    "    \n",
    "    states_geojson = open(filepath).read()\n",
    "    states_geojson = str(states_geojson).strip('\\n')\n",
    "    states_geojson = str(states_geojson).strip(';')\n",
    "    \n",
    "    json_data = json.loads(states_geojson)\n",
    "    \n",
    "    return_dic = {}\n",
    "    for feature in json_data['features']:\n",
    "        return_dic[feature['id']] = {\n",
    "            'type': feature['geometry']['type'],\n",
    "            'coordinates': feature['geometry']['coordinates']\n",
    "        }\n",
    "    \n",
    "    return return_dic\n",
    "    \n",
    "def parse_county_geojson():\n",
    "    ''' Returns a dict where each key corresponds to one a string\n",
    "    of '{:02d}-{:03d}'.format(state_code, county_code) and its value \n",
    "    to the coordinates from the geojson for the county'''\n",
    "    \n",
    "    filepath = './input_data/geojson/us_counties.geojson'\n",
    "    \n",
    "    counties_geojson = open(filepath).read()\n",
    "    counties_geojson = str(counties_geojson).strip('\\n')\n",
    "    counties_geojson = str(counties_geojson).strip(';')\n",
    "    \n",
    "    json_data = json.loads(counties_geojson)\n",
    "    \n",
    "    return_dic = {}\n",
    "    for feature in json_data['features']:\n",
    "        key = feature['properties']['STATEFP'] + '-' + feature['properties']['COUNTYFP']\n",
    "        return_dic[key] = {\n",
    "            'type': feature['geometry']['type'],\n",
    "            'coordinates': feature['geometry']['coordinates']\n",
    "        }\n",
    "    \n",
    "    return return_dic\n",
    "\n",
    "def parse_census_geojson():\n",
    "    ''' Returns a dict where each key corresponds to one a string\n",
    "    of '{:02d}-{:03d}-{}'.format(state_code, county_code, census_tract_number)\n",
    "    and its value to the coordinates from the geojson for the county'''\n",
    "    \n",
    "    path = './input_data/geojson/census_tracts/'\n",
    "    files = check_output(['ls', path]).decode('utf8').split('\\n')\n",
    "    \n",
    "    files_to_parse = []\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.isdir(filepath):\n",
    "            files_to_parse.append(filepath)\n",
    "            \n",
    "    return_dic = {}\n",
    "    for filepath in files_to_parse:\n",
    "        census_geojson = open(filepath).read()\n",
    "        census_geojson = str(census_geojson).strip('\\n')\n",
    "        census_geojson = str(census_geojson).strip(';')\n",
    "    \n",
    "        json_data = json.loads(census_geojson)\n",
    "        \n",
    "        for feature in json_data['features']:\n",
    "\n",
    "            key = '-'.join([\n",
    "                '{:02d}'.format(int(feature['properties']['STATEFP'])),\n",
    "                '{:03d}'.format(int(feature['properties']['COUNTYFP'])),\n",
    "                feature['properties']['TRACTCE'][:4] + '.' + feature['properties']['TRACTCE'][4:]\n",
    "            ])\n",
    "            return_dic[key] = {\n",
    "                'type': feature['geometry']['type'],\n",
    "                'coordinates': feature['geometry']['coordinates']\n",
    "            }\n",
    "\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./input_data/hmda_data_average_california' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b23712688de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcensus_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./input_data/hmda_data_average_california\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcensus_average\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/SIM/DataMining/.dma/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/SIM/DataMining/.dma/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/SIM/DataMining/.dma/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/SIM/DataMining/.dma/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/SIM/DataMining/.dma/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./input_data/hmda_data_average_california' does not exist"
     ]
    }
   ],
   "source": [
    "census_average = pd.read_csv(\"./input_data/hmda_data_average_california\", delimiter=\",\")\n",
    "\n",
    "census_average.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving :: 01 of 1 to './export/json/2016_California_HDMA.json'\n",
      "Finished\n",
      "census_keys_found 8805\n",
      "census_keys_not_found 1138\n"
     ]
    }
   ],
   "source": [
    "'''Generates a JSON File with the required map data to display data interactively on the map.'''\n",
    "\n",
    "state_geojson_lookup = parse_state_geojson()\n",
    "county_geojson_lookup = parse_county_geojson()\n",
    "census_geojson_lookup = parse_census_geojson()\n",
    "\n",
    "census_keys_found = 0\n",
    "census_keys_not_found = 0\n",
    "\n",
    "def get_geojson_dict(state_id=None, county_id=None, census_tract_number=None, kind=None):\n",
    "    \n",
    "    global census_keys_not_found\n",
    "    global census_keys_found\n",
    "    \n",
    "    coordinates = None #[ ['//TODO' ] ]\n",
    "    geometry_type = 'Polygon'\n",
    "    \n",
    "    if kind is not None:\n",
    "        if kind == 'state'and state_id is not None:\n",
    "            key = '{:02d}'.format(state_id)\n",
    "            if state_geojson_lookup.get(key) is not None:\n",
    "                coordinates = state_geojson_lookup.get(key)['coordinates']\n",
    "                geometry_type = state_geojson_lookup.get(key)['type']\n",
    "        if kind == 'county'and state_id is not None and county_id is not None:\n",
    "            key = '{:02d}-{:03d}'.format(state_id, county_id)\n",
    "            if county_geojson_lookup.get(key) is not None:\n",
    "                coordinates = county_geojson_lookup.get(key)['coordinates']\n",
    "                geometry_type = county_geojson_lookup.get(key)['type']\n",
    "        if kind == 'census' and state_id is not None and county_id is not None and census_tract_number is not None:\n",
    "            # TODO: Make sure the ids are formatted properly\n",
    "            key = '-'.join([\n",
    "                '{:02d}'.format(state_id),\n",
    "                '{:03d}'.format(county_id),\n",
    "                str('{:04.2f}'.format(float(census_tract_number))).zfill(7)\n",
    "            ])\n",
    "            if census_geojson_lookup.get(key) is not None:\n",
    "                census_keys_found += 1\n",
    "                coordinates = census_geojson_lookup.get(key)['coordinates']\n",
    "                geometry_type = census_geojson_lookup.get(key)['type']\n",
    "            else:\n",
    "                census_keys_not_found += 1\n",
    "\n",
    "    return {\n",
    "        'type': 'Feature',\n",
    "        'geometry': {\n",
    "            'type': geometry_type,\n",
    "             'coordinates': coordinates\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_census_dict(census_tract, census_tract_number, county_code, state_code):\n",
    "    return {\n",
    "        'census_tract': census_tract,\n",
    "        'census_tract_number': census_tract_number,\n",
    "        'geojson': get_geojson_dict(state_id=state_code, \n",
    "                                    county_id=county_code, \n",
    "                                    census_tract_number=census_tract_number, \n",
    "                                    kind='census'),\n",
    "    }\n",
    "\n",
    "def get_county_dict(df, county, county_code, state_code):\n",
    "    filtered_df = df.loc[df['county_code'] == county_code]\n",
    "    # TODO: figure out how to deal with faulty census tracts\n",
    "    filtered_df = filtered_df.dropna(axis=0, how='any', subset=['census_tract_number'])\n",
    "    census_tracts = filtered_df[['census_tracts', 'census_tract_number']].drop_duplicates()\n",
    "    return {\n",
    "        'county': county,\n",
    "        'county_code': county_code,\n",
    "        'geojson': get_geojson_dict(state_id=state_code, county_id=county_code, kind='county'),\n",
    "        'census_tracts': [get_census_dict(ct, ctn, county_code, state_code) for (ct, ctn) in census_tracts.values ]\n",
    "    }\n",
    "\n",
    "def get_state_dict(df, state, state_code):\n",
    "    filtered_df = df.loc[df['state_code'] == state_code]\n",
    "    counties = filtered_df[['county', 'county_code']].drop_duplicates()\n",
    "    return {\n",
    "        'state': state,\n",
    "        'state_code': state_code,\n",
    "        'geojson': get_geojson_dict(state_id=state_code, kind='state'),\n",
    "        'counties': [get_county_dict(filtered_df, c, cc, state_code) for (c, cc) in counties.values ]\n",
    "    }\n",
    "\n",
    "   \n",
    "    \n",
    "verbose = True\n",
    "path = './export/json'\n",
    "\n",
    "states = census_lookup[['state', 'state_code']].drop_duplicates()\n",
    "count = 0\n",
    "for (state, state_code) in states.values:\n",
    "    count += 1\n",
    "    export_dict = get_state_dict(census_lookup, state, state_code)\n",
    "\n",
    "    filename = '2016_{}_HDMA.json'.format(state)\n",
    "    filepath = os.path.join(path, filename)\n",
    "    verbose and print(\"Saving :: {:02d} of {} to '{}'\".format(count, len(states.values), filepath))\n",
    "    export_to_json(path, filename, export_dict)        \n",
    "\n",
    "    \n",
    "print('Finished')\n",
    "print('census_keys_found', census_keys_found)\n",
    "print('census_keys_not_found', census_keys_not_found)\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
