{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: SVM + Neural Networks #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>eyecolor</th>\n",
       "      <th>height</th>\n",
       "      <th>miles</th>\n",
       "      <th>brothers</th>\n",
       "      <th>sisters</th>\n",
       "      <th>computertime</th>\n",
       "      <th>exercise</th>\n",
       "      <th>exercisehours</th>\n",
       "      <th>musiccds</th>\n",
       "      <th>playgames</th>\n",
       "      <th>watchtv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>second</td>\n",
       "      <td>green</td>\n",
       "      <td>73.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>third</td>\n",
       "      <td>other</td>\n",
       "      <td>71.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>fourth</td>\n",
       "      <td>hazel</td>\n",
       "      <td>75.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1415</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>second</td>\n",
       "      <td>brown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>616</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>fourth</td>\n",
       "      <td>hazel</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender  age    year eyecolor  height  miles  brothers  sisters  \\\n",
       "0        1303   male   20  second    green    73.0  210.0         0        1   \n",
       "1          36   male   20   third    other    71.0   90.0         1        0   \n",
       "2         489   male   22  fourth    hazel    75.0  200.0         0        1   \n",
       "3        1415   male   19  second    brown    72.0   35.0         2        2   \n",
       "4         616   male   22  fourth    hazel    71.0   15.0         2        1   \n",
       "\n",
       "   computertime exercise  exercisehours  musiccds  playgames  watchtv  \n",
       "0          10.0      Yes            5.0      50.0        1.0     15.0  \n",
       "1          15.0      Yes            4.0      10.0        0.0      1.0  \n",
       "2           1.0      Yes            2.0     150.0        1.0     10.0  \n",
       "3          20.0      Yes            5.0     100.0        0.0      7.0  \n",
       "4          10.0      Yes            7.0      10.0        0.0      5.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 1###\n",
    "Calculate a baseline accuracy measure using the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.a**  \n",
    "Find the majority class in the training set. If you always predicted this class in the training set, what would your accuracy be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       1590\n",
       "unique         2\n",
       "top       female\n",
       "freq         855\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5377358490566038"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = df_train.gender.count()\n",
    "train_female = df_train.where(df_train.gender=='female').gender.count()\n",
    "train_male = df_train.where(df_train.gender=='male').gender.count()\n",
    "train_pred = np.maximum(train_female, train_male)/train_size\n",
    "train_acc = train_pred\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.b**   \n",
    "If you always predicted this same class (majority from the training set) in the test set, what would your accuracy be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        398\n",
       "unique         2\n",
       "top       female\n",
       "freq         208\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5226130653266332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = df_test.gender.count()\n",
    "test_female = df_test.where(df_test.gender=='female').gender.count()\n",
    "test_male = df_test.where(df_test.gender=='male').gender.count()\n",
    "test_freq = test_female/test_size\n",
    "test_acc = np.minimum(test_freq, train_pred)\n",
    "test_acc\n",
    "#measured value – accepted value) ÷ accepted value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 2 ###\n",
    "Get started with Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "Choose a NN implementation and specify which you choose. Be sure the implementation allows you to modify the number of hidden layers and hidden nodes per layer.  \n",
    "\n",
    "NOTE: When possible, specify the logsig (sigmoid/logistc) function as the transfer function for the output node and use Levenberg-Marquardt backpropagation (lbfgs). It is possible to specify logsig or logistic in Sklearn MLPclassifier (Neural net).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.a**   \n",
    "Train a neural network with a single 10 node hidden layer. Only use the Height feature of the dataset to predict the Gender. You will have to change Gender to a 0 and 1 class. After training, use your trained model to predict the class using the height feature from the training set. What was the accuracy of this prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1590/1590 [==============================] - 0s 142us/step - loss: 0.7993 - acc: 0.4623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1167dc160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "y_train = df_train['gender'].apply(lambda x: 0 if x == 'male' else 1).values.reshape(-1,1)\n",
    "x_train = df_train['height'].values.reshape(-1,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=1))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.b**  \n",
    "Take the trained model from question 2.b and use it to predict the test set. This can be accomplished by taking the trained model and giving it the Height feature values from the test set. What is the accuracy of this model on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7148509082482688, 0.4773869355719293]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_test['gender'].apply(lambda x: 0 if x == 'male' else 1).values.reshape(-1,1)\n",
    "x_test = df_test['height'].values.reshape(-1,1)\n",
    "\n",
    "model.evaluate(x_test, y_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.c**   \n",
    "Neural Networks tend to prefer smaller, normalized feature values. Try taking the log of the height feature in both training and testing sets or use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values. Repeat question 2.c with the log version and the normalized and centered version of this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1590/1590 [==============================] - 0s 6us/step - loss: 0.7345 - acc: 0.4623\n",
      "Epoch 2/2\n",
      "1590/1590 [==============================] - 0s 6us/step - loss: 0.7266 - acc: 0.4623\n",
      "398/398 [==============================] - 0s 7us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7170084592085987, 0.4773869355719293]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train['height'].apply('log').values.reshape(-1,1)\n",
    "x_test = df_test['height'].apply('log').values.reshape(-1,1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=256)\n",
    "model.evaluate(x_test, y_test, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1590/1590 [==============================] - 0s 6us/step - loss: 0.7535 - acc: 0.4623\n",
      "Epoch 2/2\n",
      "1590/1590 [==============================] - 0s 6us/step - loss: 0.7475 - acc: 0.4623\n",
      "398/398 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7378595676553908, 0.47738693287624184]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(df_train['height'].values.reshape(-1,1))\n",
    "\n",
    "x_test = scaler.fit_transform(df_test['height'].values.reshape(-1,1))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=256)\n",
    "model.evaluate(x_test, y_test, batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 3 ###\n",
    "Get started with Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "Chose a SVM implementation and specify which you choose. Be sure the implementation allows you to choose between linear and RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.a**   \n",
    "Use the same dataset from 2.a using the linear kernel to find training set prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8465408805031447"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "y_train = df_train['gender'].apply(lambda x: 0 if x == 'male' else 1).values.reshape(-1,1)\n",
    "x_train = df_train['height'].values.reshape(-1,1)\n",
    "y_test = df_test['gender'].apply(lambda x: 0 if x == 'male' else 1).values.reshape(-1,1)\n",
    "x_test = df_test['height'].values.reshape(-1,1)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.b**   \n",
    "Use the same dataset from 2.a using the linear kernel to find test set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542713567839196"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.c**   \n",
    "Use the same dataset from 2.a using the RBF kernel  to find training set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8465408805031447"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.d**   \n",
    "Use the same dataset from 2.a using the RBF kernel  to find test set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542713567839196"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.e**   \n",
    "Use the same dataset from 2.c (log) using the RBF to find test set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542713567839196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "x_train = df_train['height'].apply('log').values.reshape(-1,1)\n",
    "x_test = df_test['height'].apply('log').values.reshape(-1,1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.f**   \n",
    "Z-score is a normalization technique. It is the value of a feature minus the average value for that feature in the training set, divided by the standard deviation of that feature in the training set. Repeat question 3.e using Z-score and note if there is any difference in accuracy and comment on why there is a change or no change in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542713567839196"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train['height'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std()).values.reshape(-1,1)\n",
    "x_test = df_test['height'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std()).values.reshape(-1,1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 4 ###\n",
    "The rest of features in this dataset barring a few are categorical. Neither ML method accepts categorical features, so transform year, eyecolor, exercise into a set of binary features, one feature per unique original feature value, and mark the binary feature as ‘1’ if the feature value matches the original value and ‘0’ otherwise. Using only these binary variable transformed features, train and predict the class of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train4 = df_train[['year', 'eyecolor', 'exercise']]\n",
    "df_test4 = df_test[['year', 'eyecolor', 'exercise']]\n",
    "\n",
    "X_train = df_train4.to_dict('records')\n",
    "y_train = df_train['gender']\n",
    "\n",
    "X_test = df_test4.to_dict('records')\n",
    "y_test = df_test['gender']\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit([\"male\", \"female\"])\n",
    "y_train = le.transform(y_train).reshape(-1,1)\n",
    "y_test = le.transform(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.a**    \n",
    "What was your accuracy using Neural Network with a single 10 node hidden layer? During training, use a maximum number of iterations of 50. (Expected training time: ~15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1590/1590 [==============================] - 0s 295us/step - loss: 0.6914 - acc: 0.5245\n",
      "Epoch 2/50\n",
      "1590/1590 [==============================] - 0s 70us/step - loss: 0.6907 - acc: 0.5346\n",
      "Epoch 3/50\n",
      "1590/1590 [==============================] - 0s 56us/step - loss: 0.6904 - acc: 0.5371\n",
      "Epoch 4/50\n",
      "1590/1590 [==============================] - 0s 70us/step - loss: 0.6903 - acc: 0.5365\n",
      "Epoch 5/50\n",
      "1590/1590 [==============================] - 0s 64us/step - loss: 0.6903 - acc: 0.5377\n",
      "Epoch 6/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.6902 - acc: 0.5377\n",
      "Epoch 7/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6901 - acc: 0.5377\n",
      "Epoch 8/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6900 - acc: 0.5377\n",
      "Epoch 9/50\n",
      "1590/1590 [==============================] - 0s 45us/step - loss: 0.6900 - acc: 0.5377\n",
      "Epoch 10/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.6900 - acc: 0.5377\n",
      "Epoch 11/50\n",
      "1590/1590 [==============================] - 0s 88us/step - loss: 0.6899 - acc: 0.5377\n",
      "Epoch 12/50\n",
      "1590/1590 [==============================] - 0s 70us/step - loss: 0.6898 - acc: 0.5377\n",
      "Epoch 13/50\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.6898 - acc: 0.5377\n",
      "Epoch 14/50\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.6897 - acc: 0.5377\n",
      "Epoch 15/50\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: 0.6897 - acc: 0.5377\n",
      "Epoch 16/50\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: 0.6896 - acc: 0.5377\n",
      "Epoch 17/50\n",
      "1590/1590 [==============================] - 0s 54us/step - loss: 0.6897 - acc: 0.5377\n",
      "Epoch 18/50\n",
      "1590/1590 [==============================] - 0s 54us/step - loss: 0.6895 - acc: 0.5377\n",
      "Epoch 19/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6895 - acc: 0.5377\n",
      "Epoch 20/50\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.6895 - acc: 0.5377\n",
      "Epoch 21/50\n",
      "1590/1590 [==============================] - 0s 73us/step - loss: 0.6894 - acc: 0.5377\n",
      "Epoch 22/50\n",
      "1590/1590 [==============================] - 0s 55us/step - loss: 0.6894 - acc: 0.5377\n",
      "Epoch 23/50\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: 0.6893 - acc: 0.5377\n",
      "Epoch 24/50\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: 0.6892 - acc: 0.5377\n",
      "Epoch 25/50\n",
      "1590/1590 [==============================] - 0s 50us/step - loss: 0.6892 - acc: 0.5377\n",
      "Epoch 26/50\n",
      "1590/1590 [==============================] - 0s 46us/step - loss: 0.6892 - acc: 0.5377\n",
      "Epoch 27/50\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: 0.6891 - acc: 0.5377\n",
      "Epoch 28/50\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: 0.6891 - acc: 0.5377\n",
      "Epoch 29/50\n",
      "1590/1590 [==============================] - 0s 55us/step - loss: 0.6891 - acc: 0.5377\n",
      "Epoch 30/50\n",
      "1590/1590 [==============================] - 0s 55us/step - loss: 0.6890 - acc: 0.5377\n",
      "Epoch 31/50\n",
      "1590/1590 [==============================] - 0s 60us/step - loss: 0.6890 - acc: 0.5377\n",
      "Epoch 32/50\n",
      "1590/1590 [==============================] - 0s 72us/step - loss: 0.6889 - acc: 0.5377\n",
      "Epoch 33/50\n",
      "1590/1590 [==============================] - 0s 73us/step - loss: 0.6888 - acc: 0.5377\n",
      "Epoch 34/50\n",
      "1590/1590 [==============================] - 0s 65us/step - loss: 0.6888 - acc: 0.5377\n",
      "Epoch 35/50\n",
      "1590/1590 [==============================] - 0s 54us/step - loss: 0.6888 - acc: 0.5377\n",
      "Epoch 36/50\n",
      "1590/1590 [==============================] - 0s 48us/step - loss: 0.6887 - acc: 0.5377\n",
      "Epoch 37/50\n",
      "1590/1590 [==============================] - 0s 50us/step - loss: 0.6887 - acc: 0.5377\n",
      "Epoch 38/50\n",
      "1590/1590 [==============================] - 0s 47us/step - loss: 0.6886 - acc: 0.5377\n",
      "Epoch 39/50\n",
      "1590/1590 [==============================] - 0s 47us/step - loss: 0.6887 - acc: 0.5377\n",
      "Epoch 40/50\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: 0.6885 - acc: 0.5377\n",
      "Epoch 41/50\n",
      "1590/1590 [==============================] - 0s 50us/step - loss: 0.6885 - acc: 0.5377\n",
      "Epoch 42/50\n",
      "1590/1590 [==============================] - 0s 56us/step - loss: 0.6884 - acc: 0.5377\n",
      "Epoch 43/50\n",
      "1590/1590 [==============================] - 0s 68us/step - loss: 0.6885 - acc: 0.5377\n",
      "Epoch 44/50\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.6884 - acc: 0.5377\n",
      "Epoch 45/50\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: 0.6884 - acc: 0.5377\n",
      "Epoch 46/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6883 - acc: 0.5377\n",
      "Epoch 47/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6882 - acc: 0.5377\n",
      "Epoch 48/50\n",
      "1590/1590 [==============================] - 0s 40us/step - loss: 0.6882 - acc: 0.5377\n",
      "Epoch 49/50\n",
      "1590/1590 [==============================] - 0s 44us/step - loss: 0.6882 - acc: 0.5377\n",
      "Epoch 50/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6881 - acc: 0.5377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1171effd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 170us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6892389697046136, 0.5226130659256748]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 4.b**    \n",
    "What was your accuracy using a SVM with RBF kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585427135678392"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 5###\n",
    "Using a NN, does height + eye color predict the test set class better by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.a**  \n",
    "Keeping the original feature values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1590/1590 [==============================] - 1s 344us/step - loss: 0.7005 - acc: 0.5377\n",
      "Epoch 2/10\n",
      "1590/1590 [==============================] - 0s 65us/step - loss: 0.6919 - acc: 0.5377\n",
      "Epoch 3/10\n",
      "1590/1590 [==============================] - 0s 66us/step - loss: 0.6892 - acc: 0.5377\n",
      "Epoch 4/10\n",
      "1590/1590 [==============================] - 0s 52us/step - loss: 0.6887 - acc: 0.5377\n",
      "Epoch 5/10\n",
      "1590/1590 [==============================] - 0s 76us/step - loss: 0.6881 - acc: 0.5377\n",
      "Epoch 6/10\n",
      "1590/1590 [==============================] - 0s 54us/step - loss: 0.6879 - acc: 0.5377\n",
      "Epoch 7/10\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.6879 - acc: 0.5377\n",
      "Epoch 8/10\n",
      "1590/1590 [==============================] - 0s 50us/step - loss: 0.6883 - acc: 0.5377\n",
      "Epoch 9/10\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6876 - acc: 0.5377\n",
      "Epoch 10/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: 0.6876 - acc: 0.5377\n",
      "398/398 [==============================] - 0s 225us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6893466974622641, 0.5226130659256748]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train[['height','eyecolor']]\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "X_test = df_test[['height','eyecolor']]\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=6))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.b**  \n",
    "Taking the log of the original values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1590/1590 [==============================] - 0s 280us/step - loss: 0.7102 - acc: 0.5377\n",
      "Epoch 2/10\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: 0.6962 - acc: 0.5377\n",
      "Epoch 3/10\n",
      "1590/1590 [==============================] - 0s 56us/step - loss: 0.6933 - acc: 0.5377\n",
      "Epoch 4/10\n",
      "1590/1590 [==============================] - 0s 48us/step - loss: 0.6925 - acc: 0.5377\n",
      "Epoch 5/10\n",
      "1590/1590 [==============================] - 0s 54us/step - loss: 0.6924 - acc: 0.5377\n",
      "Epoch 6/10\n",
      "1590/1590 [==============================] - 0s 48us/step - loss: 0.6923 - acc: 0.5377\n",
      "Epoch 7/10\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6923 - acc: 0.5377\n",
      "Epoch 8/10\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.6923 - acc: 0.5377\n",
      "Epoch 9/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: 0.6923 - acc: 0.5377\n",
      "Epoch 10/10\n",
      "1590/1590 [==============================] - 0s 73us/step - loss: 0.6922 - acc: 0.5377\n",
      "398/398 [==============================] - 0s 211us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6952551546408303, 0.5226130659256748]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log = df_train\n",
    "df_test_log = df_test\n",
    "df_train_log['height'] = df_train['height'].apply('log')\n",
    "df_test_log['height'] = df_test['height'].apply('log')\n",
    "\n",
    "X_train = df_train_log[['height','eyecolor']]\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "X_test = df_test_log[['height','eyecolor']]\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=6))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.c**  \n",
    "Taking the Z-score of the original values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1590/1590 [==============================] - 0s 248us/step - loss: 0.7663 - acc: 0.4629\n",
      "Epoch 2/10\n",
      "1590/1590 [==============================] - 0s 50us/step - loss: 0.6791 - acc: 0.5088\n",
      "Epoch 3/10\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: 0.6382 - acc: 0.6270\n",
      "Epoch 4/10\n",
      "1590/1590 [==============================] - 0s 52us/step - loss: 0.6174 - acc: 0.7327\n",
      "Epoch 5/10\n",
      "1590/1590 [==============================] - 0s 52us/step - loss: 0.6047 - acc: 0.7767\n",
      "Epoch 6/10\n",
      "1590/1590 [==============================] - 0s 62us/step - loss: 0.5951 - acc: 0.8031\n",
      "Epoch 7/10\n",
      "1590/1590 [==============================] - 0s 62us/step - loss: 0.5871 - acc: 0.7950\n",
      "Epoch 8/10\n",
      "1590/1590 [==============================] - 0s 60us/step - loss: 0.5798 - acc: 0.8189\n",
      "Epoch 9/10\n",
      "1590/1590 [==============================] - 0s 55us/step - loss: 0.5728 - acc: 0.8088\n",
      "Epoch 10/10\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: 0.5660 - acc: 0.8145\n",
      "398/398 [==============================] - 0s 192us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9106535570106314, 0.47738693512264807]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_Z = df_train\n",
    "df_test_Z = df_test\n",
    "df_train_Z['height'] = df_train_Z['height'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std())\n",
    "df_test_Z['height'] = df_test_Z['height'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std())\n",
    "\n",
    "df_train_Z = df_train_Z[['height','eyecolor']]\n",
    "X_train = df_train_Z[['height','eyecolor']]\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "df_test_Z = df_test_Z[['height','eyecolor']]\n",
    "X_test = df_test_Z[['height','eyecolor']]\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=6))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 6 ###\n",
    "Repeat question 5 for exercise hours + eye color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1590/1590 [==============================] - 1s 402us/step - loss: nan - acc: 0.0126\n",
      "Epoch 2/10\n",
      "1590/1590 [==============================] - 0s 64us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1590/1590 [==============================] - 0s 62us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1590/1590 [==============================] - 0s 56us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1590/1590 [==============================] - 0s 60us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1590/1590 [==============================] - 0s 78us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1590/1590 [==============================] - 0s 68us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1590/1590 [==============================] - 0s 52us/step - loss: nan - acc: 0.0000e+00\n",
      "398/398 [==============================] - 0s 300us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train[['exercisehours','eyecolor']]\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "X_test = df_test[['exercisehours','eyecolor']]\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=6))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1590/1590 [==============================] - 1s 317us/step - loss: nan - acc: 0.0088\n",
      "Epoch 2/10\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1590/1590 [==============================] - 0s 60us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1590/1590 [==============================] - 0s 71us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1590/1590 [==============================] - 0s 54us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1590/1590 [==============================] - 0s 56us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: nan - acc: 0.0000e+00\n",
      "398/398 [==============================] - 0s 267us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log = df_train\n",
    "df_test_log = df_test\n",
    "df_train_log['exercisehours'] = df_train['exercisehours'].apply('log')\n",
    "df_test_log['exercisehours'] = df_test['exercisehours'].apply('log')\n",
    "\n",
    "X_train = df_train_log[['exercisehours','eyecolor']]\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "X_test = df_test_log[['exercisehours','eyecolor']]\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=6))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1590/1590 [==============================] - 1s 436us/step - loss: nan - acc: 0.0075\n",
      "Epoch 2/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1590/1590 [==============================] - 0s 74us/step - loss: nan - acc: 0.0000e+00 0s - loss: nan - acc: 0.0000e+\n",
      "Epoch 4/10\n",
      "1590/1590 [==============================] - 0s 81us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1590/1590 [==============================] - 0s 75us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1590/1590 [==============================] - 0s 71us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1590/1590 [==============================] - 0s 57us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1590/1590 [==============================] - 0s 60us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1590/1590 [==============================] - 0s 62us/step - loss: nan - acc: 0.0000e+00\n",
      "398/398 [==============================] - 0s 297us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_Z = df_train\n",
    "df_test_Z = df_test\n",
    "df_train_Z['exercisehours'] = df_train_Z['exercisehours'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std())\n",
    "df_test_Z['exercisehours'] = df_test_Z['exercisehours'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std())\n",
    "\n",
    "X_train = df_train_Z[['exercisehours','eyecolor']]\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "X_test = df_test_Z[['exercisehours','eyecolor']]\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=6))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 7###\n",
    "Combine the features from question 4, 5, and exercise hours from question 6 (using the best normalization feature set form questions 5 and 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.a**  \n",
    "What was the NN accuracy on the test set using the single 10 node hidden layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1590/1590 [==============================] - 1s 405us/step - loss: 0.7703 - acc: 0.5377\n",
      "Epoch 2/50\n",
      "1590/1590 [==============================] - 0s 56us/step - loss: 0.7273 - acc: 0.5377\n",
      "Epoch 3/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.7040 - acc: 0.5377\n",
      "Epoch 4/50\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: 0.6892 - acc: 0.5377\n",
      "Epoch 5/50\n",
      "1590/1590 [==============================] - 0s 46us/step - loss: 0.6791 - acc: 0.5377\n",
      "Epoch 6/50\n",
      "1590/1590 [==============================] - 0s 51us/step - loss: 0.6709 - acc: 0.5377\n",
      "Epoch 7/50\n",
      "1590/1590 [==============================] - 0s 58us/step - loss: 0.6637 - acc: 0.5415\n",
      "Epoch 8/50\n",
      "1590/1590 [==============================] - 0s 78us/step - loss: 0.6570 - acc: 0.5579\n",
      "Epoch 9/50\n",
      "1590/1590 [==============================] - 0s 72us/step - loss: 0.6505 - acc: 0.5899\n",
      "Epoch 10/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.6443 - acc: 0.6151\n",
      "Epoch 11/50\n",
      "1590/1590 [==============================] - 0s 58us/step - loss: 0.6382 - acc: 0.6415\n",
      "Epoch 12/50\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.6321 - acc: 0.6654\n",
      "Epoch 13/50\n",
      "1590/1590 [==============================] - 0s 60us/step - loss: 0.6262 - acc: 0.6849\n",
      "Epoch 14/50\n",
      "1590/1590 [==============================] - 0s 52us/step - loss: 0.6203 - acc: 0.6975\n",
      "Epoch 15/50\n",
      "1590/1590 [==============================] - 0s 69us/step - loss: 0.6145 - acc: 0.7088\n",
      "Epoch 16/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.6087 - acc: 0.7201\n",
      "Epoch 17/50\n",
      "1590/1590 [==============================] - 0s 68us/step - loss: 0.6030 - acc: 0.7415\n",
      "Epoch 18/50\n",
      "1590/1590 [==============================] - 0s 74us/step - loss: 0.5973 - acc: 0.7503\n",
      "Epoch 19/50\n",
      "1590/1590 [==============================] - 0s 64us/step - loss: 0.5918 - acc: 0.7535\n",
      "Epoch 20/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.5861 - acc: 0.7736\n",
      "Epoch 21/50\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: 0.5806 - acc: 0.7799\n",
      "Epoch 22/50\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: 0.5751 - acc: 0.7849\n",
      "Epoch 23/50\n",
      "1590/1590 [==============================] - 0s 55us/step - loss: 0.5696 - acc: 0.7893\n",
      "Epoch 24/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.5642 - acc: 0.7937\n",
      "Epoch 25/50\n",
      "1590/1590 [==============================] - 0s 66us/step - loss: 0.5589 - acc: 0.7950\n",
      "Epoch 26/50\n",
      "1590/1590 [==============================] - 0s 64us/step - loss: 0.5536 - acc: 0.7994\n",
      "Epoch 27/50\n",
      "1590/1590 [==============================] - 0s 64us/step - loss: 0.5483 - acc: 0.8013\n",
      "Epoch 28/50\n",
      "1590/1590 [==============================] - 0s 77us/step - loss: 0.5431 - acc: 0.8063\n",
      "Epoch 29/50\n",
      "1590/1590 [==============================] - 0s 66us/step - loss: 0.5380 - acc: 0.8113\n",
      "Epoch 30/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.5330 - acc: 0.8176\n",
      "Epoch 31/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.5280 - acc: 0.8182\n",
      "Epoch 32/50\n",
      "1590/1590 [==============================] - 0s 67us/step - loss: 0.5231 - acc: 0.8176\n",
      "Epoch 33/50\n",
      "1590/1590 [==============================] - 0s 82us/step - loss: 0.5184 - acc: 0.8182\n",
      "Epoch 34/50\n",
      "1590/1590 [==============================] - 0s 52us/step - loss: 0.5137 - acc: 0.8170\n",
      "Epoch 35/50\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: 0.5091 - acc: 0.8220\n",
      "Epoch 36/50\n",
      "1590/1590 [==============================] - 0s 73us/step - loss: 0.5045 - acc: 0.8208\n",
      "Epoch 37/50\n",
      "1590/1590 [==============================] - 0s 77us/step - loss: 0.5001 - acc: 0.8182\n",
      "Epoch 38/50\n",
      "1590/1590 [==============================] - 0s 68us/step - loss: 0.4958 - acc: 0.8189\n",
      "Epoch 39/50\n",
      "1590/1590 [==============================] - 0s 65us/step - loss: 0.4917 - acc: 0.8176\n",
      "Epoch 40/50\n",
      "1590/1590 [==============================] - 0s 69us/step - loss: 0.4876 - acc: 0.8195\n",
      "Epoch 41/50\n",
      "1590/1590 [==============================] - 0s 63us/step - loss: 0.4835 - acc: 0.8176\n",
      "Epoch 42/50\n",
      "1590/1590 [==============================] - 0s 62us/step - loss: 0.4797 - acc: 0.8226\n",
      "Epoch 43/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.4759 - acc: 0.8220\n",
      "Epoch 44/50\n",
      "1590/1590 [==============================] - 0s 53us/step - loss: 0.4722 - acc: 0.8201\n",
      "Epoch 45/50\n",
      "1590/1590 [==============================] - 0s 45us/step - loss: 0.4686 - acc: 0.8245\n",
      "Epoch 46/50\n",
      "1590/1590 [==============================] - 0s 49us/step - loss: 0.4652 - acc: 0.8239\n",
      "Epoch 47/50\n",
      "1590/1590 [==============================] - 0s 72us/step - loss: 0.4618 - acc: 0.8252\n",
      "Epoch 48/50\n",
      "1590/1590 [==============================] - 0s 78us/step - loss: 0.4585 - acc: 0.8283\n",
      "Epoch 49/50\n",
      "1590/1590 [==============================] - 0s 59us/step - loss: 0.4553 - acc: 0.8302\n",
      "Epoch 50/50\n",
      "1590/1590 [==============================] - 0s 61us/step - loss: 0.4523 - acc: 0.8302\n",
      "398/398 [==============================] - 0s 528us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.218741680509481, 0.47738693512264807]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train[['eyecolor','year', 'exercise', 'height']]\n",
    "X_train['height'] = X_train['height'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std())\n",
    "X_train = X_train.to_dict('records')\n",
    "\n",
    "#'exercisehours',\n",
    "\n",
    "X_test = df_test[['eyecolor','year', 'exercise', 'height']]\n",
    "X_test['height'] = X_test['height'].apply(lambda x: (x - df_train['height'].mean())/df_train['height'].std())\n",
    "X_test = X_test.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.fit_transform(X_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=14))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.b**  \n",
    "What was the SVM accuracy on the test set the RBF kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47738693467336685"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 8- Bonus###\n",
    "Can you improve your test set prediction accuracy by 5% or more?  \n",
    "\n",
    "See how close to that milestone of improvement you can get by modifying the tuning parameters of either Neural Networks (the number of hidden layers, number of hidden nodes in each layer, the learning rate aka mu) or with SVM (choosing kernel, C, and gamma). A great guide to tuning parameters is explained in this guide: http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. \n",
    "\n",
    "While the guide is specific to SVM and in particular the C and gamma parameters of the RBF kernel, the method applies to generally to any ML technique with tuning parameters.\n",
    "\n",
    "Please also write a paragraph in a markdown cell below with an explanation of your approach and evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
